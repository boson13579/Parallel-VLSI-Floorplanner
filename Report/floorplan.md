### 深入分析：`Floorplan` 內部的時間消耗大戶

在一次模擬退火的迭代中，主要的計算時間都花在 `perturb()` -> `pack()` -> `calculate_cost()` -> `calculate_inl()` 這個流程上。其中，`pack()` 和 `calculate_inl()` 是計算最密集的部分。

#### 1. `pack()` 函式分析

*   **用途**：將抽象的 B*-Tree 結構，透過深度優先搜尋 (DFS) 演算法，轉換為每個區塊具體的 `(x, y)` 物理座標。
*   **核心演算法**：帶有輪廓線 (Contour Line) 更新的遞迴 DFS。
*   **為什麼不能簡單地平行化？**
    *   **極強的資料相依性 (Strong Data Dependency)**：這是最主要的原因。在 DFS 的過程中，一個節點的座標**完全依賴**於其父節點的**最終座標**。
        *   左子節點的 x 座標 = 父節點的 x 座標 + 父節點的寬度。
        *   右子節點的 x 座標 = 父節點的 x 座標。
        *   所有節點的 y 座標，都依賴於一個**共享的、不斷在變動**的 `contour` 資料結構。

    *   **我可以用 `#pragma omp parallel for` 把所有節點的計算平行化嗎？**
        *   **絕對不行**。想像一下，如果所有執行緒同時開始計算所有節點的座標。執行緒 A 在計算節點 `C` 的座標時，可能它的父節點 `P` 的座標還沒有被執行緒 B 計算出來。這會導致 `C` 的座標完全錯誤。整個演算法的正確性都建立在**循序 (Sequential)** 的訪問順序上。

    *   **控制相依性 (Control Dependency)**：DFS 的遞迴路徑本身就是循序的。程式必須先完成對父節點的處理，才能決定下一步是遞迴到左子樹還是右子樹。

    *   **類比**：`pack()` 的過程就像**蓋磚牆**。你必須先把下面一排的磚塊砌好（父節點），才能在它們上面砌上一排（子節點）。你不可能讓 10 個工人同時去砌牆上的任意一塊磚，這會導致整面牆的崩塌。

**結論**：`pack()` 函式由於其演算法內在的**循序依賴性**，無法透過簡單的 OpenMP 指令進行平行化。任何試圖平行化它的行為都會破壞演算法的正確性。

#### 2. `calculate_inl()` 函式分析

這個函式更有趣，因為它內部**確實存在可以平行化的部分**，但這也恰好是解釋「為什麼細粒度平行化通常是個壞主意」的最佳範例。

讓我們將 `calculate_inl()` 的計算步驟拆解開來：

*   **步驟一：計算每個區塊中心點到佈局中心的距離平方**
    ```cpp
    // for (const auto& node : tree) { ... }
    ```
    *   **可以平行化嗎？** **可以**。每個區塊的距離計算是完全獨立的。
    *   **為什麼不這麼做？** **開銷過高 (High Overhead)**。迴圈內部的計算量極小（幾次加減法和乘法），CPU 執行這些指令可能只需要幾十個奈秒 (nanoseconds)。而啟動 OpenMP 平行區域、建立和同步執行緒的開銷，則是以微秒 (microseconds) 甚至毫秒 (milliseconds) 為單位。這就像**為了搬一本書而請來一整個搬家團隊**，準備工作的時間遠遠超過了實際搬運的時間。

*   **步驟二：對區塊按名稱排序**
    ```cpp
    // sort(block_dists.begin(), block_dists.end());
    ```
    *   **可以平行化嗎？** **理論上可以**。存在複雜的平行排序演算法。
    *   **為什麼不這麼做？** `std::sort` 本身是一個高度優化的循序演算法。要手動實作一個高效的平行排序非常困難。雖然 C++17 之後的版本支援平行策略 (`std::sort(std::execution::par, ...)`），但對於中小型規模（例如幾百個區塊）的資料，其開銷可能仍然高於循序版本。

*   **步驟三：計算累積和 (Cumulative Sum) `s_actual`**
    ```cpp
    // for (const auto& bd : block_dists) s_actual.push_back(current_sum += bd.dist_sq);
    ```
    *   **可以平行化嗎？** **不可以**（使用簡單方法）。
    *   **為什麼？** 這是典型的**迴圈攜帶相依性 (Loop-Carried Dependency)**。計算 `s_actual` 的第 `i` 個元素，**必須**先知道第 `i-1` 個元素的結果。後一次迭代的輸入，是前一次迭代的輸出。這種依賴性是無法被 `#pragma omp for` 打破的。
    *   **進階知識**：雖然存在名為「平行前綴和」(Parallel Prefix Sum / Scan) 的高等演算法可以解決這個問題，但它的實作非常複雜，完全不適用於此處。

*   **步驟四：計算線性迴歸的各項總和**
    ```cpp
    // for (int i = 0; i < n; ++i) { sum_x += ...; sum_y += ...; }
    ```
    *   **可以平行化嗎？** **可以**。這是一個典型的歸約 (Reduction) 操作。
    *   **如何實作？** `#pragma omp parallel for reduction(+:sum_x, sum_y, ...)`
    *   **為什麼不這麼做？** 原因同步驟一：**開銷過高**。迴圈內的計算同樣非常快，不值得為此啟動平行化。

---

### 總結表格

| 函式 / 步驟 | 時間複雜度 (約略) | 可簡單平行化? | 為什麼不行 / 不值得？ |
| :--- | :--- | :--- | :--- |
| **`pack()`** | O(N), N為區塊數 | **否** | **根本原因**：演算法具有內在的**資料相依性**和**控制相依性**。 |
| **`calculate_inl()`** | | | |
| ? 計算距離 | O(N) | **是** | **效能陷阱**：平行化**開銷**遠大於計算本身的收益（極細粒度）。 |
| ? 排序 | O(N log N) | 否 | `std::sort` 是循序的，平行排序實作複雜且未必更快。 |
| ? 計算累積和 | O(N) | **否** | **根本原因**：存在**迴圈攜帶相依性**。 |
| ? 計算迴歸和 | O(N) | **是** | **效能陷阱**：平行化**開銷**遠大於計算本身的收益（極細粒度）。 |

這個詳細的分析有力地證明了，對於您這個專案，**將平行化的重心放在更高層級的策略上是完全正確的設計決策**。這也將是您專案報告中一個非常有深度的技術論證點。